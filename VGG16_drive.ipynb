{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgdbOzR9JGKa2ebyp8iuyg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CiaraFarrellSETU/Dissertation_code/blob/main/VGG16_drive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Classification Using Transfer Learning (VGG-16)  \n",
        "https://muhammadrizwanmunawar.medium.com/image-classification-using-transfer-learning-vgg-16-2dc2221be34c"
      ],
      "metadata": {
        "id": "B-iu9mebtvNe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mounting google drvie"
      ],
      "metadata": {
        "id": "-SWKDQRgbf9o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvJsbrK1lxPd",
        "outputId": "c453b712-2bdd-42e9-b1ed-bd97b8458123"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount your Google Drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "importing libaries"
      ],
      "metadata": {
        "id": "gs3vDKVjbeED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "MLXxJ8sPl5H5"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "unzipping zipped file from google drive"
      ],
      "metadata": {
        "id": "h-m-U9IibVEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('/content/gdrive/MyDrive/dog_eyes.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/unzipp_data')  # Replace with desired destination directory"
      ],
      "metadata": {
        "id": "GE9a2nWztjFi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "set the path of training, testing, and validation directories"
      ],
      "metadata": {
        "id": "mDaIMT7Fbl1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = '/content/unzipp_data/dog_eyes'\n",
        "\n",
        "train_dir = '/content/unzipp_data/dog_eyes/train'\n",
        "cat_train_dir = '/content/unzipp_data/dog_eyes/train/cataract'\n",
        "healthy_train_dir = '/content/unzipp_data/dog_eyes/train/healthy'\n",
        "\n",
        "test_dir = '/content/unzipp_data/dog_eyes/test'\n",
        "cat_test_dir = '/content/unzipp_data/dog_eyes/test/cataract'\n",
        "healthy_test_dir = '/content/unzipp_data/dog_eyes/test/healthy'\n",
        "\n",
        "val_dir = '/content/unzipp_data/dog_eyes/valid'\n",
        "cat_val_dir = '/content/unzipp_data/dog_eyes/valid/cataract'\n",
        "healthy_val_dir = '/content/unzipp_data/dog_eyes/valid/healthy'"
      ],
      "metadata": {
        "id": "tOcpbJRSmOEn"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "getting data from these folders"
      ],
      "metadata": {
        "id": "8MOfjZ3zb81E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cat_train = len(os.listdir(cat_train_dir))\n",
        "num_healthy_train = len(os.listdir(healthy_train_dir))\n",
        "\n",
        "num_cat_test = len(os.listdir(cat_test_dir))\n",
        "num_healthy_test = len(os.listdir(healthy_test_dir))\n",
        "\n",
        "num_cat_val = len(os.listdir(cat_val_dir))\n",
        "num_healthy_val = len(os.listdir(healthy_val_dir))"
      ],
      "metadata": {
        "id": "tC6qlqjtqeZL"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "seeing how many training,testing and validation images there is"
      ],
      "metadata": {
        "id": "2_M1GhsAcCDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Training cat Images\",num_cat_train)\n",
        "print(\"Total Training healthy Images\",num_healthy_train)\n",
        "print(\"--\")\n",
        "print(\"Total test cat Images\",num_cat_test)\n",
        "print(\"Total test healthy Images\",num_healthy_test)\n",
        "print(\"--\")\n",
        "print(\"Total validation cat Images\",num_cat_val)\n",
        "print(\"Total validation healthy Images\",num_healthy_val)\n",
        "print(\"--\")\n",
        "\n",
        "\n",
        "total_train = num_cat_train+num_healthy_train\n",
        "total_validation = num_cat_val+num_healthy_val\n",
        "total_test = num_cat_test+num_healthy_test\n",
        "print(\"Total Training Images\",total_train)\n",
        "print(\"--\")\n",
        "print(\"Total Validation Images\",total_validation)\n",
        "print(\"--\")\n",
        "print(\"Total Testing Images\",total_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hssNna39biz",
        "outputId": "bf2ace1e-1af3-41eb-d60f-d2f21bfac84c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training cat Images 5290\n",
            "Total Training healthy Images 1530\n",
            "--\n",
            "Total test cat Images 179\n",
            "Total test healthy Images 70\n",
            "--\n",
            "Total validation cat Images 421\n",
            "Total validation healthy Images 121\n",
            "--\n",
            "Total Training Images 6820\n",
            "--\n",
            "Total Validation Images 542\n",
            "--\n",
            "Total Testing Images 249\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "resize images to (224,224) because VGG-16 only accepts that image size."
      ],
      "metadata": {
        "id": "Jfn4ud3fcOw_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE  = 224\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "3WyZo4-hrLri"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocess data (train, test, validation), which includes, rescaling and shuffling"
      ],
      "metadata": {
        "id": "BFXJErUNcP48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_gen_train = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "TQpHm6lkAgfC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_gen = image_gen_train.flow_from_directory(batch_size = batch_size,\n",
        "directory = train_dir,\n",
        "shuffle= True,\n",
        "target_size = (IMG_SHAPE,IMG_SHAPE),\n",
        "class_mode = 'binary')\n",
        "image_generator_validation = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8Yk5iQqBKkc",
        "outputId": "f4786223-8e4a-4793-a6c3-7472f694a743"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 6820 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_data_gen = image_generator_validation.flow_from_directory(batch_size=batch_size,\n",
        "directory=val_dir,\n",
        "target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "class_mode='binary')\n",
        "image_gen_test = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjUf82KnAotW",
        "outputId": "c87f777e-5362-40dd-93cd-35de03da784f"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 541 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_gen = image_gen_test.flow_from_directory(batch_size=batch_size,\n",
        "directory=test_dir,\n",
        "target_size=(IMG_SHAPE, IMG_SHAPE),\n",
        "class_mode='binary')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbJI8rKGrO4r",
        "outputId": "92cef49c-b1b6-454e-a845-633e961b39c8"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 249 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The image data generator is supposed to use the folder names as class names.  \n",
        "folder names are cataract, healthy"
      ],
      "metadata": {
        "id": "LwyWmPt-AARP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_trained_model = tf.keras.applications.VGG16(input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\")"
      ],
      "metadata": {
        "id": "_Nx2r4ZfrRXz"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in pre_trained_model.layers:\n",
        "  print(layer.name)\n",
        "layer.trainable = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1UuV4qnsx1u",
        "outputId": "c15e250a-56c2-4edb-f860-43c6b5cffe8f"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_3\n",
            "block1_conv1\n",
            "block1_conv2\n",
            "block1_pool\n",
            "block2_conv1\n",
            "block2_conv2\n",
            "block2_pool\n",
            "block3_conv1\n",
            "block3_conv2\n",
            "block3_conv3\n",
            "block3_pool\n",
            "block4_conv1\n",
            "block4_conv2\n",
            "block4_conv3\n",
            "block4_pool\n",
            "block5_conv1\n",
            "block5_conv2\n",
            "block5_conv3\n",
            "block5_pool\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "last_layer = pre_trained_model.get_layer('block5_pool')\n",
        "last_output = last_layer.output\n",
        "x = tf.keras.layers.GlobalMaxPooling2D()(last_output)\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = tf.keras.layers.Dense(2, activation='sigmoid')(x)"
      ],
      "metadata": {
        "id": "FQJAormls4I1"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "have tried different activations softmax and sigmoid"
      ],
      "metadata": {
        "id": "Z0K9DG4aLyb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Model(pre_trained_model.input, x)"
      ],
      "metadata": {
        "id": "VcFvQamWs70L"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.compile(optimizer='adam', loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=['acc'])"
      ],
      "metadata": {
        "id": "N4STnqRHs9sf"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=tf.keras.losses.categorical_crossentropy, metrics=['acc'])"
      ],
      "metadata": {
        "id": "HytuMr5Gs_3R"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "52KMRlDHtBfj",
        "outputId": "cf98e67e-ed94-4ae6-cd54-fc2346d4dc37"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Model.summary of <keras.src.engine.functional.Functional object at 0x7af9098a3dc0>>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>keras.src.engine.training.Model.summary</b><br/>def summary(line_length=None, positions=None, print_fn=None, expand_nested=False, show_trainable=False, layer_range=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py</a>Prints a string summary of the network.\n",
              "\n",
              "Args:\n",
              "    line_length: Total length of printed lines\n",
              "        (e.g. set this to adapt the display to different\n",
              "        terminal window sizes).\n",
              "    positions: Relative or absolute positions of log elements\n",
              "        in each line. If not provided, becomes\n",
              "        `[0.3, 0.6, 0.70, 1.]`. Defaults to `None`.\n",
              "    print_fn: Print function to use. By default, prints to `stdout`.\n",
              "        If `stdout` doesn&#x27;t work in your environment, change to `print`.\n",
              "        It will be called on each line of the summary.\n",
              "        You can set it to a custom function\n",
              "        in order to capture the string summary.\n",
              "    expand_nested: Whether to expand the nested models.\n",
              "        Defaults to `False`.\n",
              "    show_trainable: Whether to show if a layer is trainable.\n",
              "        Defaults to `False`.\n",
              "    layer_range: a list or tuple of 2 strings,\n",
              "        which is the starting layer name and ending layer name\n",
              "        (both inclusive) indicating the range of layers to be printed\n",
              "        in summary. It also accepts regex patterns instead of exact\n",
              "        name. In such case, start predicate will be the first element\n",
              "        it matches to `layer_range[0]` and the end predicate will be\n",
              "        the last element it matches to `layer_range[1]`.\n",
              "        By default `None` which considers all layers of model.\n",
              "\n",
              "Raises:\n",
              "    ValueError: if `summary()` is called before the model is built.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 3466);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDYlN7ErtNcU",
        "outputId": "43279a57-4247-4616-808f-fc6696cc6199"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.engine.functional.Functional at 0x7af9098a3dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "WZ_G-cLvBkan",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2050b5e9-a326-450d-9337-f7c0234f16b7"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " global_max_pooling2d_3 (Gl  (None, 512)               0         \n",
            " obalMaxPooling2D)                                               \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 1026      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14978370 (57.14 MB)\n",
            "Trainable params: 14978370 (57.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vgg_classifier = model.fit(train_data_gen,\n",
        "steps_per_epoch=(total_train//batch_size),\n",
        "epochs = 5,\n",
        "validation_data=val_data_gen,\n",
        "validation_steps=(total_validation//batch_size),\n",
        "batch_size = batch_size,\n",
        "verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        },
        "id": "ucZ1hbHrtOzA",
        "outputId": "6d7deb99-e869-43e2-d0c8-ffdb0d66a6f0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-b52d602cd50b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m vgg_classifier = model.fit(train_data_gen,\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_train\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_data_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_validation\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 2221, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/backend.py\", line 5573, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 2) are incompatible\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data_gen[0][0].shape, train_data_gen[0][1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpOnHPPRdr3y",
        "outputId": "09eeb148-1a48-435e-cbbe-95a3f5d092c4"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(val_data_gen[0][0].shape, val_data_gen[0][1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTupyx3deRNK",
        "outputId": "0c5e9afa-237e-4f9e-c5ca-31e1bac10bd8"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3) (32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train and val are the same shape so unsure why error is occuring"
      ],
      "metadata": {
        "id": "DgQS5BKweDez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.evaluate(test_data_gen,batch_size=batch_size)\n",
        "print(\"test_loss, test accuracy\",result)"
      ],
      "metadata": {
        "id": "OnKDEAWLtSw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}